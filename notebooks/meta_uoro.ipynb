{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from pdb import set_trace\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('/Users/omarschall/online-meta/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_sizes, lr_init):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.n_layers = len(layer_sizes)\n",
    "        self.n_params = 0\n",
    "        for i in range(1, self.n_layers):\n",
    "            attr = 'layer_{}'.format(i)\n",
    "            setattr(self, attr, nn.Linear(layer_sizes[i-1],\n",
    "                                          layer_sizes[i]))\n",
    "            param_size = (layer_sizes[i-1] + 1) * layer_sizes[i]\n",
    "            self.n_params += param_size\n",
    "            \n",
    "        self.param_sizes = [p.numel() for p in self.parameters()]\n",
    "        self.param_shapes = [tuple(p.shape) for p in self.parameters()]\n",
    "        self.param_cumsum = np.cumsum([0] + self.param_sizes)\n",
    "            \n",
    "        self.A = np.random.normal(0, 1, self.n_params)\n",
    "        self.B = np.random.normal(0, 1, self.n_params)\n",
    "        self.eta = np.ones(self.n_params)*lr_init\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layer_sizes[0])\n",
    "        for i_layer in range(1, self.n_layers):\n",
    "            attr = 'layer_{}'.format(i_layer)\n",
    "            layer = getattr(self, attr)\n",
    "            x = layer(x)\n",
    "            if i_layer < self.n_layers - 1:\n",
    "                x = F.relu(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def UORO_update_step(self, Q):\n",
    "\n",
    "        self.nu = np.random.choice([-1, 1], Q.shape)\n",
    "        grad = self.flatten_array([p.grad.data.numpy() for p in self.parameters()])\n",
    "        \n",
    "        self.M_projection = self.nu * grad\n",
    "        self.A_forwards = self.A - self.eta * Q\n",
    "        A_norm = norm(self.A_forwards)\n",
    "        B_norm = norm(self.B)\n",
    "        M_norm = norm(self.M_projection)\n",
    "        self.rho_0 = np.sqrt(B_norm/A_norm)\n",
    "        self.rho_1 = np.sqrt(M_norm/np.sqrt(len(self.nu)))\n",
    "        \n",
    "        self.A = self.rho_0 * self.A_forwards + self.rho_1 * self.nu\n",
    "        self.B = (1/self.rho_0) * self.B + (1/self.rho_1) * self.M_projection\n",
    "        \n",
    "    def get_updated_eta(self, mlr, test_grad):\n",
    "        \n",
    "        test_grad = self.flatten_array(test_grad)\n",
    "        self.eta -= mlr*(test_grad.dot(self.A)) * self.B\n",
    "        self.eta = np.maximum(0, self.eta)\n",
    "        \n",
    "        return np.copy(self.unflatten_array(self.eta))\n",
    "    \n",
    "    def flatten_array(self, X):\n",
    "        \"\"\"Takes list of arrays in natural shape of the network parameters\n",
    "        and returns as a flattened 1D numpy array.\"\"\"\n",
    "        \n",
    "        return np.concatenate([x.flatten() for x in X])\n",
    "            \n",
    "    def unflatten_array(self, X):\n",
    "        \"\"\"Takes flattened array and returns in natural shape for network\n",
    "        parameters.\"\"\"\n",
    "        \n",
    "        N = self.param_cumsum\n",
    "        \n",
    "        return [np.reshape(X[N[i]:N[i+1]], s) for i, s in enumerate(self.param_shapes)]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from itertools import tee\n",
    "\n",
    "class SGD_Multi_LR(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr_init=0.005):\n",
    "        \n",
    "        params, params_copy = tee(params)\n",
    "        LR = [lr_init*torch.ones(p.shape) for p in params]\n",
    "        defaults = dict(lr=LR)\n",
    "        super(SGD_Multi_LR, self).__init__(params_copy, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(SGD_Multi_LR, self).__setstate__(state)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Performs a single optimization step.\"\"\"\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p, lr in zip(group['params'], group['lr']):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                p_change = -lr * d_p\n",
    "                p.data.add_(p_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, epoch, r=0.001, mlr=0.00001,\n",
    "          report_interval=1000):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % report_interval == 0 and batch_idx > 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "        ### --- METALEARNING --- ###\n",
    "        \n",
    "        #Approximate the Hessian\n",
    "        A = model.unflatten_array(model.A)\n",
    "        \n",
    "        model_plus = copy(model)\n",
    "        for p, a in zip(model_plus.parameters(), A):\n",
    "            perturbation = torch.from_numpy(r*a).type(torch.FloatTensor)\n",
    "            p.data += perturbation\n",
    "        \n",
    "        model_plus.train()\n",
    "        output = model_plus(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        model_minus = copy(model)\n",
    "        for p, a in zip(model_minus.parameters(), A):\n",
    "            p.data -= torch.from_numpy(r*a).type(torch.FloatTensor)\n",
    "        \n",
    "        model_minus.train()\n",
    "        output = model_plus(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        g_plus = [p.grad.data for p in model_plus.parameters()]\n",
    "        g_minus = [p.grad.data for p in model_minus.parameters()]\n",
    "        Q = (model.flatten_array(g_plus) - model.flatten_array(g_minus))/(2*r)\n",
    "        \n",
    "        test_grad = get_test_grad(model, test_loader=test_loader)\n",
    "        model.UORO_update_step(Q)\n",
    "        new_eta = model.get_updated_eta(mlr, test_grad=test_grad)\n",
    "        \n",
    "        #set_trace()\n",
    "        \n",
    "        for lr, eta in zip(optimizer.param_groups[0]['lr'], new_eta):\n",
    "            lr.data = torch.from_numpy(eta).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_grad(model, test_loader):\n",
    "    test_model = copy(model)\n",
    "    test_model.train()\n",
    "    for data, target in test_loader:\n",
    "        #set_trace()\n",
    "        #TODO: MAKE THIS SAMPLE FROM DIFFERENT PARTS OF THE TEST DATA!\n",
    "        output = test_model(data)\n",
    "        test_loss = F.nll_loss(output, target)\n",
    "        test_loss.backward()\n",
    "        break\n",
    "        \n",
    "    return [p.grad.data.numpy() for p in test_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2049, Accuracy: 9388/10000 (94%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1306, Accuracy: 9605/10000 (96%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1028, Accuracy: 9677/10000 (97%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0867, Accuracy: 9729/10000 (97%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0748, Accuracy: 9768/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "test_batch_size = 100\n",
    "epochs = 5\n",
    "lr = 1e-1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "model = Net([784, 1000, 200, 10], lr_init=lr)\n",
    "optimizer = SGD_Multi_LR(model.parameters(), lr_init=lr)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, train_loader, test_loader, optimizer, epoch, mlr=0.00005)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c2a80fda0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1ae48b70>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_LRs = [float(LR.mean()) for LR in optimizer.param_groups[0]['lr']]\n",
    "std_LRs = [float(LR.std()) for LR in optimizer.param_groups[0]['lr']]\n",
    "plt.errorbar(range(len(mean_LRs)), mean_LRs, yerr=std_LRs)\n",
    "plt.axhline(y=lr, color='C1')\n",
    "param_types = ['W', 'b']\n",
    "labels = ['Layer-{} {}'.format(i//2, param_types[i%2]) for i in range(len(mean_LRs))]\n",
    "plt.xticks(range(len(mean_LRs)), labels)\n",
    "plt.legend(['Init LR', 'Final LR'])\n",
    "#plt.ylim([0,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00999774131923914"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(optimizer.param_groups[0]['lr'][0].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
